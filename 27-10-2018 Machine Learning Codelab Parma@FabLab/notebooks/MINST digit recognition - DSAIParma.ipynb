{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mxnet as mx \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  pixel9  pixel10  pixel11  pixel12  pixel13  \n",
       "0       0       0        0        0        0        0  \n",
       "1       0       0        0        0        0        0  \n",
       "2       0       0        0        0        0        0  \n",
       "3       0       0        0        0        0        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.iloc[0:4, 0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.asarray(train1.iloc[0:33600,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=np.asarray(train1.iloc[33600:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train=train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cv=cv[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=np.reshape(_train, (_train.shape[0],1,28,28))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx=np.reshape(_cv, (_cv.shape[0],1,28,28))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/pietro/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix=3\n",
    "img=np.asarray(np.matrix(trainx[ix,0,:,:]))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=np.asarray(train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvy=np.asarray(cv[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FULLY CONNECTED NEURAL NETWORK\n",
    "==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "Y= mx.symbol.Variable('softmax_label') \n",
    "\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=data)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "nlin3 = mx.sym.Activation(data=fc1, act_type=\"relu\") \n",
    "\n",
    "# output fullc\n",
    "fc3 = mx.sym.FullyConnected(data=nlin3, num_hidden=10)\n",
    "# Softmax output\n",
    "SNN = mx.symbol.SoftmaxOutput(data=fc3, label=Y, name=\"SNN\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNN_model = mx.mod.Module(symbol=SNN, label_names =['softmax_label'], context=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 25691.58 samples/sec\taccuracy=0.807164\n",
      "INFO:root:Epoch[0] Train-accuracy=0.919333\n",
      "INFO:root:Epoch[0] Time cost=1.408\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.933810\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 24465.87 samples/sec\taccuracy=0.943632\n",
      "INFO:root:Epoch[1] Train-accuracy=0.953704\n",
      "INFO:root:Epoch[1] Time cost=1.365\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.954286\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 24888.19 samples/sec\taccuracy=0.963831\n",
      "INFO:root:Epoch[2] Train-accuracy=0.966741\n",
      "INFO:root:Epoch[2] Time cost=1.627\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.961190\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 24366.09 samples/sec\taccuracy=0.973980\n",
      "INFO:root:Epoch[3] Train-accuracy=0.976000\n",
      "INFO:root:Epoch[3] Time cost=1.385\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.965714\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 24050.02 samples/sec\taccuracy=0.980846\n",
      "INFO:root:Epoch[4] Train-accuracy=0.982148\n",
      "INFO:root:Epoch[4] Time cost=1.720\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.968571\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 23954.51 samples/sec\taccuracy=0.985274\n",
      "INFO:root:Epoch[5] Train-accuracy=0.986370\n",
      "INFO:root:Epoch[5] Time cost=1.424\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.971786\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 24057.36 samples/sec\taccuracy=0.989502\n",
      "INFO:root:Epoch[6] Train-accuracy=0.989704\n",
      "INFO:root:Epoch[6] Time cost=1.630\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.973690\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 22639.45 samples/sec\taccuracy=0.992040\n",
      "INFO:root:Epoch[7] Train-accuracy=0.992296\n",
      "INFO:root:Epoch[7] Time cost=1.599\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.974643\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 14969.08 samples/sec\taccuracy=0.994328\n",
      "INFO:root:Epoch[8] Train-accuracy=0.994519\n",
      "INFO:root:Epoch[8] Time cost=1.920\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.973690\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 23560.69 samples/sec\taccuracy=0.996269\n",
      "INFO:root:Epoch[9] Train-accuracy=0.996148\n",
      "INFO:root:Epoch[9] Time cost=1.431\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.973214\n",
      "INFO:root:Epoch[10] Batch [200]\tSpeed: 22929.49 samples/sec\taccuracy=0.997313\n",
      "INFO:root:Epoch[10] Train-accuracy=0.997704\n",
      "INFO:root:Epoch[10] Time cost=1.451\n",
      "INFO:root:Epoch[10] Validation-accuracy=0.973929\n",
      "INFO:root:Epoch[11] Batch [200]\tSpeed: 23966.96 samples/sec\taccuracy=0.998458\n",
      "INFO:root:Epoch[11] Train-accuracy=0.998444\n",
      "INFO:root:Epoch[11] Time cost=1.417\n",
      "INFO:root:Epoch[11] Validation-accuracy=0.974762\n",
      "INFO:root:Epoch[12] Batch [200]\tSpeed: 24212.15 samples/sec\taccuracy=0.998856\n",
      "INFO:root:Epoch[12] Train-accuracy=0.999037\n",
      "INFO:root:Epoch[12] Time cost=1.410\n",
      "INFO:root:Epoch[12] Validation-accuracy=0.975119\n",
      "INFO:root:Epoch[13] Batch [200]\tSpeed: 17209.84 samples/sec\taccuracy=0.999303\n",
      "INFO:root:Epoch[13] Train-accuracy=0.999630\n",
      "INFO:root:Epoch[13] Time cost=1.748\n",
      "INFO:root:Epoch[13] Validation-accuracy=0.974762\n",
      "INFO:root:Epoch[14] Batch [200]\tSpeed: 24002.44 samples/sec\taccuracy=0.999502\n",
      "INFO:root:Epoch[14] Train-accuracy=0.999630\n",
      "INFO:root:Epoch[14] Time cost=1.410\n",
      "INFO:root:Epoch[14] Validation-accuracy=0.975476\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(trainx, trainy, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(cvx, cvy, batch_size)\n",
    "\n",
    "SNN_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.05, 'momentum': 0.9},\n",
    "                eval_metric='acc', \n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size=batch_size, frequent=200),\n",
    "                num_epoch=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DEEP FULLY CONNECTED NEURAL NETWORK\n",
    "==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "Y= mx.symbol.Variable('softmax_label') \n",
    "\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=data)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "nlin1 = mx.sym.Activation(data=fc1, act_type=\"relu\") \n",
    "\n",
    "# second fullc layer\n",
    "fc2 = mx.symbol.FullyConnected(data=nlin1, num_hidden=500)\n",
    "nlin2 = mx.sym.Activation(data=fc2, act_type=\"relu\") \n",
    "\n",
    "# third fullc layer\n",
    "fc3 = mx.symbol.FullyConnected(data=nlin2, num_hidden=500)\n",
    "nlin3 = mx.sym.Activation(data=fc3, act_type=\"relu\") \n",
    "\n",
    "# output fullc\n",
    "fc4 = mx.sym.FullyConnected(data=nlin3, num_hidden=10)\n",
    "# Softmax output\n",
    "DNN = mx.symbol.SoftmaxOutput(data=fc4, label=Y, name=\"DNN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_model = mx.mod.Module(symbol=DNN, label_names =['softmax_label'], context=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 8885.92 samples/sec\taccuracy=0.108905\n",
      "INFO:root:Epoch[0] Train-accuracy=0.180222\n",
      "INFO:root:Epoch[0] Time cost=3.767\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.372500\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 9020.95 samples/sec\taccuracy=0.735771\n",
      "INFO:root:Epoch[1] Train-accuracy=0.904963\n",
      "INFO:root:Epoch[1] Time cost=3.961\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.931667\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 8828.85 samples/sec\taccuracy=0.936418\n",
      "INFO:root:Epoch[2] Train-accuracy=0.952074\n",
      "INFO:root:Epoch[2] Time cost=3.776\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.956548\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 8976.39 samples/sec\taccuracy=0.957512\n",
      "INFO:root:Epoch[3] Train-accuracy=0.966593\n",
      "INFO:root:Epoch[3] Time cost=3.766\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.961786\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 8593.95 samples/sec\taccuracy=0.970945\n",
      "INFO:root:Epoch[4] Train-accuracy=0.976593\n",
      "INFO:root:Epoch[4] Time cost=4.418\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.967024\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 7986.53 samples/sec\taccuracy=0.978358\n",
      "INFO:root:Epoch[5] Train-accuracy=0.980815\n",
      "INFO:root:Epoch[5] Time cost=4.333\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.961786\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 8486.32 samples/sec\taccuracy=0.981244\n",
      "INFO:root:Epoch[6] Train-accuracy=0.987926\n",
      "INFO:root:Epoch[6] Time cost=3.953\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.972500\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 8479.39 samples/sec\taccuracy=0.987512\n",
      "INFO:root:Epoch[7] Train-accuracy=0.989630\n",
      "INFO:root:Epoch[7] Time cost=3.997\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.972024\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 8616.96 samples/sec\taccuracy=0.989005\n",
      "INFO:root:Epoch[8] Train-accuracy=0.990667\n",
      "INFO:root:Epoch[8] Time cost=3.890\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.972143\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 8639.54 samples/sec\taccuracy=0.991592\n",
      "INFO:root:Epoch[9] Train-accuracy=0.989407\n",
      "INFO:root:Epoch[9] Time cost=3.883\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.973810\n",
      "INFO:root:Epoch[10] Batch [200]\tSpeed: 8661.87 samples/sec\taccuracy=0.990597\n",
      "INFO:root:Epoch[10] Train-accuracy=0.992667\n",
      "INFO:root:Epoch[10] Time cost=4.145\n",
      "INFO:root:Epoch[10] Validation-accuracy=0.973452\n",
      "INFO:root:Epoch[11] Batch [200]\tSpeed: 8640.61 samples/sec\taccuracy=0.990846\n",
      "INFO:root:Epoch[11] Train-accuracy=0.993630\n",
      "INFO:root:Epoch[11] Time cost=4.239\n",
      "INFO:root:Epoch[11] Validation-accuracy=0.973690\n",
      "INFO:root:Epoch[12] Batch [200]\tSpeed: 8648.70 samples/sec\taccuracy=0.993682\n",
      "INFO:root:Epoch[12] Train-accuracy=0.993630\n",
      "INFO:root:Epoch[12] Time cost=3.933\n",
      "INFO:root:Epoch[12] Validation-accuracy=0.973452\n",
      "INFO:root:Epoch[13] Batch [200]\tSpeed: 8656.15 samples/sec\taccuracy=0.992985\n",
      "INFO:root:Epoch[13] Train-accuracy=0.996741\n",
      "INFO:root:Epoch[13] Time cost=4.249\n",
      "INFO:root:Epoch[13] Validation-accuracy=0.976190\n",
      "INFO:root:Epoch[14] Batch [200]\tSpeed: 8413.84 samples/sec\taccuracy=0.996468\n",
      "INFO:root:Epoch[14] Train-accuracy=0.997926\n",
      "INFO:root:Epoch[14] Time cost=3.990\n",
      "INFO:root:Epoch[14] Validation-accuracy=0.976905\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(trainx, trainy, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(cvx, cvy, batch_size)\n",
    "\n",
    "DNN_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.05, 'momentum': 0.9},\n",
    "                eval_metric='acc', \n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size=batch_size, frequent=200),\n",
    "                num_epoch=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CONVOLUTIONAL NEURAL NETWORK\n",
    "==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "Y= mx.symbol.Variable('softmax_label') \n",
    "\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "nlin1 = mx.sym.Activation(data=conv1, act_type=\"relu\")\n",
    "pool1 = mx.sym.Pooling(data=nlin1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "drop1 = mx.symbol.Dropout(data=pool1,p=0.5)\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=drop1, kernel=(5,5), num_filter=40)\n",
    "nlin2 = mx.sym.Activation(data=conv2, act_type=\"relu\")\n",
    "pool2 = mx.sym.Pooling(data=nlin2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "drop2 = mx.symbol.Dropout(data=pool2,p=0.5)\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=drop2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "nlin3 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# output fullc\n",
    "fc2 = mx.sym.FullyConnected(data=nlin3, num_hidden=10)\n",
    "# Softmax output\n",
    "CNN = mx.symbol.SoftmaxOutput(data=fc2, label=Y,name=\"CCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = mx.mod.Module(symbol=CNN, label_names =['softmax_label'], context=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 1549.95 samples/sec\taccuracy=0.107761\n",
      "INFO:root:Epoch[0] Train-accuracy=0.396370\n",
      "INFO:root:Epoch[0] Time cost=22.700\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.907381\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 1655.47 samples/sec\taccuracy=0.906567\n",
      "INFO:root:Epoch[1] Train-accuracy=0.946519\n",
      "INFO:root:Epoch[1] Time cost=21.996\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.976429\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 1445.82 samples/sec\taccuracy=0.954129\n",
      "INFO:root:Epoch[2] Train-accuracy=0.962296\n",
      "INFO:root:Epoch[2] Time cost=22.050\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.983333\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 1573.92 samples/sec\taccuracy=0.963433\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(trainx, trainy, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(cvx, cvy, batch_size)\n",
    "\n",
    "CNN_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.05, 'momentum': 0.9},\n",
    "                eval_metric='acc', \n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size=batch_size, frequent=200),              \n",
    "                num_epoch=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
